{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yaallah.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2NeQVyBXfwA"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFBkwC5KXqm8"
      },
      "source": [
        "VIDEOS_PATH = \"/content/dataset/raw_videos\"\n",
        "IMAGES_PATH = \"/content/dataset/images\"\n",
        "IMAGE_DIMS = (320, 240)\n",
        "FRAME_SKIP = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R44t6bMXshf"
      },
      "source": [
        "dataset = {\n",
        "    \"gate\":[\n",
        "            {\"id\":\"1ZgB6H3BvIpY2hGlxRZyNWqxNzqXEcaOd\", \"time\":[0, 16]},\n",
        "            {\"id\":\"1-PWKUPQN7fpccPvIP-qwHYOUG7rlIZcg\", \"time\":[9, 19]},\n",
        "            {\"id\":\"1EC5jTVkmp8F38CekmKGOI5cozlIanap2\", \"time\":[0, 12]}, \n",
        "            {\"id\":\"1DYceEMmv_SE-u9a2JeHDdBkE2dbLUykM\", \"time\":[0, 16]},\n",
        "            {\"id\":\"11i-PGRHadcdM_I_Ac4eY5s1squMjwcSW\", \"time\":[0, 17]},\n",
        "            {\"id\":\"1Pxg3wq_NI6kixxmiGrN3i8zYY6lSZtCT\", \"time\":[12, 22]},\n",
        "            {\"id\":\"1DFxOBErILaqwLnUWnp_LAA0w6nrCestE\", \"time\":[0, 13]},\n",
        "            {\"id\":\"1tkY7PNNUdDmEJEMwtBo1AEGre2ej7-eq\", \"time\":[4, 16]},\n",
        "            {\"id\":\"1H31XijetfseAYMLRcrgV9zHy97jN5pjJ\", \"time\":[6, None]},\n",
        "            {\"id\":\"1068GQ6TbXUbnnYdhEp93wEGV-gZND5Si\", \"time\":[0, 12]},\n",
        "            {\"id\":\"1cyaXGP8Y3ew_kWOAWqY1wqvnSL7LcV-V\", \"time\":[0, 9]},\n",
        "            {\"id\":\"18G8lNKye2jF4XA9Wp3ayulAWp9t42Lg-\", \"time\":[0, 4]},\n",
        "            {\"id\":\"1IPJXXQGx1qaLWm21DiQ0Ykf95GeKgLEK\", \"time\":[0, 13]},\n",
        "\n",
        "\n",
        "            {\"id\":\"1npIbYXxzQ4248YWSHbiZeHTiVGtj2-qG\", \"time\":[2, 12]},\n",
        "            {\"id\":\"1gWoRZb8TkpEi2Db9BlLYFHNQCXXQCObU\", \"time\":[30, 41]},\n",
        "            {\"id\":\"1y6JIdFgTv6gmXpr7wNgRq_B6CRmQZNFh\", \"time\":[0, 8]},\n",
        "            {\"id\":\"1HsKdqkTtDqr03BHxvhrMGYrfey29HJIT\", \"time\":[23, 36]},\n",
        "            {\"id\":\"1HsKdqkTtDqr03BHxvhrMGYrfey29HJIT\", \"time\":[39, 44]},\n",
        "            {\"id\":\"1HsKdqkTtDqr03BHxvhrMGYrfey29HJIT\", \"time\":[57, 60]},\n",
        "            {\"id\":\"1HsKdqkTtDqr03BHxvhrMGYrfey29HJIT\", \"time\":[73, 80]},\n",
        "            {\"id\":\"1HsKdqkTtDqr03BHxvhrMGYrfey29HJIT\", \"time\":[0, 12]},\n",
        "            \n",
        "            {\"id\":\"13BU46vHAALG3vchYreWsftnibYi22jyX\", \"time\":[5, 22]},\n",
        "            {\"id\":\"13BU46vHAALG3vchYreWsftnibYi22jyX\", \"time\":[31, 48]},\n",
        "            {\"id\":\"195IVlfMqHFBq9PLGVp9ULgtQSCHJZTV_\", \"time\":[8, 13]}\n",
        "            \n",
        "            ],\n",
        "\n",
        "       \n",
        "    \"non_gate\":[\n",
        "                \n",
        "                {\"id\":\"1DFxOBErILaqwLnUWnp_LAA0w6nrCestE\", \"time\":[14, None]},\n",
        "                {\"id\":\"1tkY7PNNUdDmEJEMwtBo1AEGre2ej7-eq\", \"time\":[22, None]},\n",
        "                # {\"id\":\"1oTNF3aS3Z_UbB6DDlwWButbILlARovl9\", \"time\":[0, None]},\n",
        "                {\"id\":\"1cyaXGP8Y3ew_kWOAWqY1wqvnSL7LcV-V\", \"time\":[13, None]},\n",
        "                {\"id\":\"1npIbYXxzQ4248YWSHbiZeHTiVGtj2-qG\", \"time\":[32, None]},\n",
        "                {\"id\":\"1y6JIdFgTv6gmXpr7wNgRq_B6CRmQZNFh\", \"time\":[20, None]},\n",
        "                {\"id\":\"18G8lNKye2jF4XA9Wp3ayulAWp9t42Lg-\", \"time\":[6, None]}   ]        \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TJcuQZPXu8B"
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-8oEFyOX-Ar"
      },
      "source": [
        "# Create dataset directories\n",
        "os.makedirs(VIDEOS_PATH, exist_ok=True)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "os.makedirs(\"/content/train/gate\", exist_ok=True)\n",
        "os.makedirs(\"/content/train/non\", exist_ok=True)\n",
        "\n",
        "\n",
        "os.makedirs(\"/content/test/gate\", exist_ok=True)\n",
        "os.makedirs(\"/content/test/non\", exist_ok=True)\n",
        "\n",
        "\n",
        "os.makedirs(\"/content/validation/gate\", exist_ok=True)\n",
        "os.makedirs(\"/content/validation/non\", exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLmZ1YyYYOTz",
        "outputId": "a11af6f3-c68b-476e-874a-44e56ca84547",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "# Loop over classes\n",
        "for current_class, videos in dataset.items():\n",
        "  print(\"Processing {} class.\".format(current_class))\n",
        "  img_idx = 0\n",
        "  # Create a directory for the class in videos and images path\n",
        "  os.makedirs(os.path.join(VIDEOS_PATH, current_class), exist_ok=True)\n",
        "  os.makedirs(os.path.join(IMAGES_PATH, current_class), exist_ok=True)\n",
        "  os.chdir(os.path.join(VIDEOS_PATH, current_class))\n",
        "  # Loop over videos in each class\n",
        "  for index, video in enumerate(videos):\n",
        "    # Download the video\n",
        "    downloaded = drive.CreateFile({'id':video[\"id\"]})\n",
        "    video_name = str(index) + \".mp4\"\n",
        "    print(\"Processing {}\".format(video_name))\n",
        "    downloaded.GetContentFile(video_name)\n",
        "    # Open the video\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "    # Get the frame rate\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    # Get start frame\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, round(fps * video[\"time\"][0]))\n",
        "    # Get end frame\n",
        "    if video[\"time\"][1] == None:\n",
        "      end_frame = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    else:\n",
        "      end_frame = round(fps * video[\"time\"][1])\n",
        "\n",
        "    frame_idx = 0\n",
        "\n",
        "    while cap.isOpened() and cap.get(cv2.CAP_PROP_POS_FRAMES) < end_frame:\n",
        "      # Read frame\n",
        "      ret, frame = cap.read()\n",
        "      if not ret:\n",
        "        break\n",
        "\n",
        "      if frame_idx % FRAME_SKIP == 0:\n",
        "        # Save image\n",
        "        cv2.imwrite(os.path.join(IMAGES_PATH, current_class, str(img_idx) + \".jpg\"), frame)\n",
        "        img_idx += 1\n",
        "\n",
        "      frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "  os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing gate class.\n",
            "Processing 0.mp4\n",
            "Processing 1.mp4\n",
            "Processing 2.mp4\n",
            "Processing 3.mp4\n",
            "Processing 4.mp4\n",
            "Processing 5.mp4\n",
            "Processing 6.mp4\n",
            "Processing 7.mp4\n",
            "Processing 8.mp4\n",
            "Processing 9.mp4\n",
            "Processing 10.mp4\n",
            "Processing 11.mp4\n",
            "Processing 12.mp4\n",
            "Processing 13.mp4\n",
            "Processing 14.mp4\n",
            "Processing 15.mp4\n",
            "Processing 16.mp4\n",
            "Processing 17.mp4\n",
            "Processing 18.mp4\n",
            "Processing 19.mp4\n",
            "Processing 20.mp4\n",
            "Processing 21.mp4\n",
            "Processing 22.mp4\n",
            "Processing 23.mp4\n",
            "Processing non_gate class.\n",
            "Processing 0.mp4\n",
            "Processing 1.mp4\n",
            "Processing 2.mp4\n",
            "Processing 3.mp4\n",
            "Processing 4.mp4\n",
            "Processing 5.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUKxCE3BYSSt",
        "outputId": "eb325b4d-50f4-46f1-c564-46df9c8a10a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('number of gate - ',len(os.listdir(\"/content/dataset/images/gate\"))) #printing the number of cat training images\n",
        "print('number of non  - ',len(os.listdir(\"/content/dataset/images/non_gate\"))) #printing the number of dog training images\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of gate -  3846\n",
            "number of non  -  4630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U60IElz_Ya_C"
      },
      "source": [
        " **Data_spliting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MZARiQAYYjb"
      },
      "source": [
        "gate_dir = \"/content/dataset/images/gate\" #storing the cats training images\n",
        "non_dir =\"/content/dataset/images/non_gate\" #storing the cats training images\n",
        "\n",
        "gate=os.listdir(gate_dir)\n",
        "non=os.listdir(non_dir)\n",
        "\n",
        "train_gate = gate[:int(0.8*len(gate))]\n",
        "train_non = non[:int(0.8*len(non))]\n",
        "\n",
        "valid_gate = gate [int(0.8*len(gate)):int(0.986*len(gate))]\n",
        "valid_non= non [int(0.8*len(non)) : int(0.986*len(non))]\n",
        "\n",
        "test_gate = gate[int(0.986*len(gate)) :int(len(gate))]\n",
        "test_non = non[int(0.986*len(non)) :int(len(non))]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ6VYxlEcPkh",
        "outputId": "ece44525-a2c6-4a62-9036-0a0ca8d7c5de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('number of train gate - ',len(train_gate))\n",
        "print('number of test gate - ',len(test_gate)) \n",
        "print('number of valid gate - ',len(valid_gate)) \n",
        "\n",
        "print('number of train non - ',len(train_non)) \n",
        "print('number of test non - ',len(test_non)) \n",
        "print('number of valid non - ',len(valid_non)) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train gate -  3076\n",
            "number of test gate -  54\n",
            "number of valid gate -  716\n",
            "number of train non -  3704\n",
            "number of test non -  65\n",
            "number of valid non -  861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSFW4adfczAu"
      },
      "source": [
        "for file in gate:\n",
        "    if file in train_gate:\n",
        "        src_dir = gate_dir+'/'+str(file)\n",
        "        dst_dir = \"/content/train/gate\"\n",
        "        shutil.move(src_dir,dst_dir)\n",
        "\n",
        "    elif file in valid_gate:\n",
        "        src_dir = gate_dir+'/'+str(file)\n",
        "        dst_dir = \"/content/validation/gate\"\n",
        "        shutil.move(src_dir,dst_dir)\n",
        "    elif file in test_gate:\n",
        "        src_dir = gate_dir+'/'+str(file)\n",
        "        dst_dir = \"/content/test/gate\"\n",
        "        shutil.move(src_dir,dst_dir)\n",
        "    else:\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMRJL__vc9xy"
      },
      "source": [
        "for file in non:\n",
        "    if file in train_non:\n",
        "        src_dir = non_dir+'/'+str(file)\n",
        "        dst_dir = \"/content/train/non\"\n",
        "        shutil.move(src_dir,dst_dir)\n",
        "\n",
        "    elif file in valid_non:\n",
        "        src_dir = non_dir+'/'+str(file)\n",
        "        dst_dir = \"/content/validation/non\"\n",
        "        shutil.move(src_dir,dst_dir)\n",
        "    elif file in test_non:\n",
        "        src_dir = non_dir+'/'+str(file)\n",
        "        dst_dir = \"/content/test/non\"\n",
        "        shutil.move(src_dir,dst_dir)\n",
        "    else:\n",
        "        pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emVPB_sVdBfQ",
        "outputId": "292d552f-e31b-4d36-9c3f-589f8bd53be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('number of train gate - ',len(os.listdir(\"/content/train/gate\"))) \n",
        "print('number of train non  - ',len(os.listdir(\"/content/train/non\")))\n",
        "\n",
        "print('number of test gate - ',len(os.listdir(\"/content/test/gate\"))) \n",
        "print('number of test non - ',len(os.listdir(\"/content/test/non\")))\n",
        "\n",
        "print('number of valid gate  - ',len(os.listdir(\"/content/validation/gate\"))) \n",
        "print('number of valid non - ',len(os.listdir(\"/content/validation/non\"))) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of train gate -  3076\n",
            "number of train non  -  3704\n",
            "number of test gate -  54\n",
            "number of test non -  65\n",
            "number of valid gate  -  716\n",
            "number of valid non -  861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFaV09onzXTG"
      },
      "source": [
        "**CNN_Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUyHW1LodD36"
      },
      "source": [
        "import pandas as pd #making some of our usual imports inorder to solve the problem in hand \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.models import Sequential #importing our deep learing libraries\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_3HdNDMdHrJ"
      },
      "source": [
        "data_generator = ImageDataGenerator(rescale = 1./250,zoom_range = 0.2) #we are converting our RGB photo into array numbers for better computation and processing of our model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLOMZcuRdLlA",
        "outputId": "a80c67ba-bd6d-49a3-982b-5df513c469fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 64 #accessing all our data both training and testing\n",
        "training_data = data_generator.flow_from_directory(directory = \"/content/train\",\n",
        "                                                  target_size = (150,150),\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  class_mode  = 'binary')\n",
        "\n",
        "validation_data = data_generator.flow_from_directory(directory = \"/content/validation\",\n",
        "                                                  target_size = (150,150),\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  class_mode  = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6780 images belonging to 2 classes.\n",
            "Found 1577 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evr9nXesdOKk"
      },
      "source": [
        "model = Sequential() #making our CNN\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = training_data.image_shape))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(rate = 0.3))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(rate = 0.2))\n",
        "model.add(Conv2D(filters = 126, kernel_size = (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "model.add(Dropout(rate = 0.15))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units = 512, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.15))\n",
        "model.add(Dense(units = 64, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.1))\n",
        "model.add(Dense(units = len(set(training_data.classes)), activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvFAib_WdRw9",
        "outputId": "269b40f4-fd06-44f8-d2dd-5f7b5b29f48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "fitted_model = model.fit_generator(training_data,\n",
        "                        steps_per_epoch = 105,\n",
        "                        epochs =3,\n",
        "                        validation_data = validation_data,\n",
        "                        validation_steps = 24)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-8e247fda2d30>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/3\n",
            "105/105 [==============================] - 257s 2s/step - loss: 0.4370 - accuracy: 0.8346 - val_loss: 0.1243 - val_accuracy: 0.9701\n",
            "Epoch 2/3\n",
            "105/105 [==============================] - 256s 2s/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.0242 - val_accuracy: 0.9922\n",
            "Epoch 3/3\n",
            "105/105 [==============================] - 258s 2s/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0248 - val_accuracy: 0.9948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnoi6xDGTQUV",
        "outputId": "d7fd18db-5ea4-4ee8-c09f-f297f32eaad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 126)       72702     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 126)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 17, 17, 126)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 36414)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               18644480  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 18,769,536\n",
            "Trainable params: 18,769,536\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgEDsG2UdXzc"
      },
      "source": [
        "def testing_image(image_directory): #testing out our model\n",
        "    test_image = image.load_img(image_directory, target_size = (150, 150))\n",
        "    test_image = image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis = 0)\n",
        "    result = model.predict(x = test_image)\n",
        "    if result[0][0]  == 1:\n",
        "        prediction = 'gate'\n",
        "        # print(prediction)\n",
        "        return 1\n",
        "    else:\n",
        "        prediction = 'none gate'\n",
        "        # print(prediction)\n",
        "        return 0\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FilrxmaVdjSH"
      },
      "source": [
        "test_dir = \"/content/test\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da5LuedpdoFi",
        "outputId": "931720fa-c8eb-46be-a599-7bfad051a887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('number of test non - ',len(os.listdir(\"/content/test/gate\")))\n",
        "test_gate=os.listdir(\"/content/test/gate\")\n",
        "test_non=os.listdir(\"/content/test/non\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of test non -  54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q6_fAksdoK_",
        "outputId": "acd2a9ec-e187-4b42-deb5-742068c6973f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TP=0\n",
        "FP=0\n",
        "for file in test_gate:\n",
        "    x=testing_image(test_dir + '/gate/' + str(file))\n",
        "    if x==1 :\n",
        "        TP+=1\n",
        "    else:\n",
        "        FP+=1\n",
        "\n",
        "print(TP,FP)\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQwtYHxfd0JM",
        "outputId": "75b0f3f6-c96f-4154-b99e-c4d12ff25bd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('number of test non - ',len(os.listdir(\"/content/test/non\")))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of test non -  65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou1xpkind02s",
        "outputId": "c0404230-d53d-436a-d163-5da115bce02b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TN=0\n",
        "FN=0\n",
        "for file in test_non:\n",
        "    x=testing_image(test_dir + '/non/' + str(file))\n",
        "    if x==0 :\n",
        "        TN+=1\n",
        "    else:\n",
        "        FN+=1\n",
        "\n",
        "print(TN,FN)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PgZaX8Yd5yZ",
        "outputId": "6c237607-c4c5-4c92-de42-38f46a3cf357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_Accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
        "print(test_Accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9243697478991597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8TZd1kGm8bi",
        "outputId": "c2c2706f-06dd-4886-c056-58418f01033f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.save(\"CNN.model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: CNN.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAClSdNpjxjW",
        "outputId": "0d32d5e9-4cb0-4d70-d643-01d1b1a786fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!zip -r GateDetection_NeuralNetwork.zip CNN.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: CNN.model/ (stored 0%)\n",
            "  adding: CNN.model/saved_model.pb (deflated 89%)\n",
            "  adding: CNN.model/assets/ (stored 0%)\n",
            "  adding: CNN.model/variables/ (stored 0%)\n",
            "  adding: CNN.model/variables/variables.index (deflated 67%)\n",
            "  adding: CNN.model/variables/variables.data-00000-of-00001 (deflated 9%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaJ8VuW2kg3N"
      },
      "source": [
        "# print(testing_image(\"/content/download.jpeg\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OehA_wIoUVGa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}